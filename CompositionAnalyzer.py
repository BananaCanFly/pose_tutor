# crop_advisor.py
import cv2
import numpy as np

import mediapipe as mp
import torch

# MediaPipe Pose ä¸­çš„å…³é”®å…³èŠ‚ï¼ˆé¿å…è£åˆ‡ï¼‰
CRITICAL_JOINT_IDS = {
    13: "å·¦æ‰‹è‚˜",
    14: "å³æ‰‹è‚˜",
    15: "å·¦æ‰‹è…•",
    16: "å³æ‰‹è…•",
    25: "å·¦è†ç›–",
    26: "å³è†ç›–",
    27: "å·¦è„šè¸",
    28: "å³è„šè¸",
}
mp_pose = mp.solutions.pose

def mask_hip_below(frame, keypoints):
    """
    å°†å›¾åƒä¸­é«‹éƒ¨ä»¥ä¸‹çš„éƒ¨åˆ†è®¾ç½®ä¸ºé»‘è‰²ï¼Œé«‹éƒ¨ä»¥ä¸Šä¿ç•™ã€‚

    å‚æ•°:
    - frame: è¾“å…¥å›¾åƒï¼ˆBGRæ ¼å¼ï¼‰
    - keypoints: åŒ…å«äººä½“å…³é”®ç‚¹çš„å­—å…¸ï¼Œå‡è®¾æœ‰ 'hip_left' å’Œ 'hip_right'

    è¿”å›:
    - ä¿®æ”¹åçš„å›¾åƒ
    """

    # è·å–å›¾åƒçš„é«˜å’Œå®½
    height, width = frame.shape[:2]

    mp_pose = mp.solutions.pose
    # å‡è®¾æˆ‘ä»¬æœ‰å·¦å³é«‹éƒ¨çš„ y åæ ‡

    hip_left = keypoints[mp_pose.PoseLandmark.LEFT_HIP]
    hip_right = keypoints[mp_pose.PoseLandmark.RIGHT_HIP]

    if hip_left is None or hip_right is None:
        print("é«‹éƒ¨å…³é”®ç‚¹ç¼ºå¤±!")
        return frame

    # è·å–é«‹éƒ¨çš„å¹³å‡ y åæ ‡
    hip_y = (hip_left['y'] + hip_right['y']) / 2 * height  # å°† [0, 1] èŒƒå›´çš„ y åæ ‡è½¬ä¸ºå®é™…åƒç´ 

    # å°†é«‹éƒ¨ä»¥ä¸‹çš„åŒºåŸŸè®¾ç½®ä¸ºé»‘è‰²
    frame[int(hip_y):, :] = 0  # å°† y åæ ‡ä¸‹æ–¹çš„æ‰€æœ‰åƒç´ ç½®ä¸ºé»‘è‰²ï¼ˆBGRä¸­ä¸º0ï¼‰

    return frame

def get_box(frame, results):
    """
    è®¡ç®—äººç‰©çš„æœ€é«˜ç‚¹ï¼ˆè¾¹ç•Œæ¡†çš„é¡¶éƒ¨ä¸­å¿ƒç‚¹ï¼‰
    """

    # è·å–æ£€æµ‹ç»“æœï¼ˆboxes, labels, scoresï¼‰
    boxes = results.xywh[0][:, :-2]  # è·å–æ‰€æœ‰çš„è¾¹ç•Œæ¡†
    scores = results.xywh[0][:, -2]  # å¾—åˆ°ç½®ä¿¡åº¦
    labels = results.xywh[0][:, -1]  # ç±»åˆ«åç§°

    best_box = None
    best_score = -1.0

    PERSON_CLASS_ID = 0
    for box, score, label in zip(boxes, scores, labels):
        if int(label) != PERSON_CLASS_ID:
            continue

        if score > best_score:
            best_score = score
            best_box = box

    return best_box

def get_highest_point(frame, results):
    """
    è®¡ç®—äººç‰©çš„æœ€é«˜ç‚¹ï¼ˆè¾¹ç•Œæ¡†çš„é¡¶éƒ¨ä¸­å¿ƒç‚¹ï¼‰
    """

    # è·å–æ£€æµ‹ç»“æœï¼ˆboxes, labels, scoresï¼‰
    boxes = results.xywh[0][:, :-2]  # è·å–æ‰€æœ‰çš„è¾¹ç•Œæ¡†
    scores = results.xywh[0][:, -2]  # å¾—åˆ°ç½®ä¿¡åº¦
    labels = results.xywh[0][:, -1]  # ç±»åˆ«åç§°

    # æå–æ¯ä¸ªè¾¹ç•Œæ¡†çš„ä¸Šä¸‹å·¦å³åæ ‡
    highest_point = 1
    for box, score, label in zip(boxes, scores, labels):
        # print(box, score, label)
        if label != 0 or score < 0.5:  # å¦‚æœç½®ä¿¡åº¦ä½äº0.5ï¼Œå¿½ç•¥
            continue

        # è·å–è¾¹ç•Œæ¡†çš„åæ ‡ (x_center, y_center, width, height)
        x_center, y_center, w, h = box

        # è®¡ç®—è¾¹ç•Œæ¡†çš„é¡¶éƒ¨ä¸­å¿ƒç‚¹
        highest_point = (y_center - h / 2)/frame.shape[0]  # é¡¶éƒ¨çš„yåæ ‡
        # top_x = x_center  # é¡¶éƒ¨çš„xåæ ‡ä¸ä¸­å¿ƒç›¸åŒ

        # è®°å½•æœ€é«˜ç‚¹çš„ä½ç½®
        # if highest_point is None or top_y < highest_point[1]:
            # highest_point = (top_x, top_y)

    return highest_point


def get_edge_point(frame, results):
    """
    è®¡ç®—äººç‰©çš„æœ€é«˜ç‚¹ï¼ˆè¾¹ç•Œæ¡†çš„é¡¶éƒ¨ä¸­å¿ƒç‚¹ï¼‰
    """

    # è·å–æ£€æµ‹ç»“æœï¼ˆboxes, labels, scoresï¼‰
    boxes = results.xywh[0][:, :-2]  # è·å–æ‰€æœ‰çš„è¾¹ç•Œæ¡†
    scores = results.xywh[0][:, -2]  # å¾—åˆ°ç½®ä¿¡åº¦
    labels = results.xywh[0][:, -1]  # ç±»åˆ«åç§°

    # æå–æ¯ä¸ªè¾¹ç•Œæ¡†çš„ä¸Šä¸‹å·¦å³åæ ‡
    left_point = 0
    right_point = 1
    for box, score, label in zip(boxes, scores, labels):
        # print(box, score, label)
        if label != 0 or score < 0.5:  # å¦‚æœç½®ä¿¡åº¦ä½äº0.5ï¼Œå¿½ç•¥
            continue

        # è·å–è¾¹ç•Œæ¡†çš„åæ ‡ (x_center, y_center, width, height)
        x_center, y_center, w, h = box

        # è®¡ç®—è¾¹ç•Œæ¡†çš„é¡¶éƒ¨ä¸­å¿ƒç‚¹
        left_point = (x_center - w / 2)/frame.shape[1]  # é¡¶éƒ¨çš„yåæ ‡
        right_point = (x_center + w / 2)/frame.shape[1]
        # top_x = x_center  # é¡¶éƒ¨çš„xåæ ‡ä¸ä¸­å¿ƒç›¸åŒ

        # è®°å½•æœ€é«˜ç‚¹çš„ä½ç½®
        # if highest_point is None or top_y < highest_point[1]:
            # highest_point = (top_x, top_y)

    return [left_point, right_point]


def estimate_knee_height(landmarks, visibility_threshold=0.5):
    """
    æ ¹æ®è‚©éƒ¨å’Œé«‹éƒ¨çš„å…³é”®ç‚¹æ¨æµ‹è†ç›–é«˜åº¦
    :param landmarks: Mediapipe Pose æ¨¡å‹è¿”å›çš„å…³é”®ç‚¹åˆ—è¡¨
    :param visibility_threshold: å…³é”®ç‚¹å¯è§æ€§é˜ˆå€¼ï¼Œé»˜è®¤ä¸º 0.5
    :return: æ¨æµ‹çš„è†ç›–é«˜åº¦ï¼ˆå‚ç›´åæ ‡æ¯”ä¾‹ï¼‰
    """

    # æå–è‚©éƒ¨å’Œé«‹éƒ¨å…³é”®ç‚¹
    left_shoulder = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER]
    right_shoulder = landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER]
    left_hip = landmarks[mp_pose.PoseLandmark.LEFT_HIP]
    right_hip = landmarks[mp_pose.PoseLandmark.RIGHT_HIP]
    # print("å·¦è„šè¸ï¼Œå³è„šè¸ï¼Œå·¦è†ç›–ï¼Œå³è†ç›–",landmarks[mp_pose.PoseLandmark.LEFT_ANKLE]['y'],landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE]['y'],
    #       landmarks[mp_pose.PoseLandmark.LEFT_KNEE]['y'], landmarks[mp_pose.PoseLandmark.RIGHT_KNEE]['y'])

    # print(left_shoulder, right_shoulder, left_hip, right_hip)

    # å¯è§†æ€§åˆ¤æ–­
    if left_shoulder["visibility"] > visibility_threshold and right_shoulder["visibility"] > visibility_threshold and \
            left_hip["visibility"] > visibility_threshold and right_hip["visibility"] > visibility_threshold:

        # è®¡ç®—è‚©éƒ¨å’Œé«‹éƒ¨ä¹‹é—´çš„å‚ç›´è·ç¦»ï¼ˆYåæ ‡çš„å¹³å‡å€¼ï¼‰
        shoulder_y = (left_shoulder["y"] + right_shoulder["y"]) / 2
        hip_y = (left_hip["y"] + right_hip["y"]) / 2

        # è†ç›–é«˜åº¦å‡è®¾åœ¨é«‹éƒ¨åˆ°è‚©éƒ¨ä¹‹é—´çš„70%ä½ç½®
        knee_y = hip_y + abs(shoulder_y - hip_y) * 0.7  # è†ç›–ä½ç½®æ˜¯é«‹éƒ¨åˆ°è‚©éƒ¨çš„70%é«˜åº¦

        return knee_y

    # å¦‚æœå…³é”®ç‚¹ä¸å¯è§ï¼Œè¿”å› None
    return None


# def analyze_crop_and_zoom(frame, keypoints, yolo_box):
#     """
#     åˆ†ææ‹ç…§å»ºè®®ï¼ŒåŒ…æ‹¬å¤´éƒ¨ç•™ç™½ã€è†ç›–è„šè¸è£å‰ªã€èƒ³è†Šæ˜¾ç¤ºã€äººç‰©å±…ä¸­ç­‰
#     å‚æ•°:
#     - frame: å½“å‰å¸§å›¾åƒï¼ˆOpenCVæ ¼å¼ï¼‰
#     - keypoints: äººç‰©çš„å…³é”®ç‚¹åˆ—è¡¨ï¼ŒåŒ…å«å¤´éƒ¨ã€è‚©è†€ã€è‚˜éƒ¨ã€è†ç›–ã€è„šè¸ç­‰éƒ¨ä½çš„åæ ‡
#
#     è¿”å›:
#     - dict: åŒ…å«è£å‰ªå’Œç¼©æ”¾å»ºè®®çš„ä¿¡æ¯
#     """
#
#     # print(keypoints)
#     suggestions = []
#     height, width = frame.shape[:2]
#
#     # è·å–å…³é”®ç‚¹
#     # head_y = keypoints[0]['y']  # å¤´éƒ¨ä½ç½®
#     # shoulder_left_y = keypoints[11]['y']  # å·¦è‚©
#     # shoulder_right_y = keypoints[12]['y']  # å³è‚©
#     knee_left_y = keypoints[25]['y']  # å·¦è†
#     knee_right_y = keypoints[26]['y']  # å³è†
#     ankle_left_y = keypoints[27]['y']  # å·¦è„šè¸
#     ankle_right_y = keypoints[28]['y']  # å³è„šè¸
#     # elbow_left_x = keypoints[13]['x']  # å·¦è‚˜
#     # elbow_right_x = keypoints[14]['x']  # å³è‚˜
#     # wrist_left_y = keypoints[15]['y']  # å·¦æ‰‹è…•
#     # wrist_right_y = keypoints[16]['y']  # å³æ‰‹è…•
#
#     # 1. å…ˆé™åˆ†è¾¨ç‡ï¼ˆéå¸¸å…³é”®ï¼‰
#
#     frame = cv2.resize(frame, (320, 320))
#     edge_frame = mask_hip_below(frame, keypoints)
#
#     elbow_left_x, foot_y, elbow_right_x, head_y = yolo_box
#     # head_y = get_highest_point(edge_frame, results)
#     # elbow_left_x, elbow_right_x = get_edge_point(frame, results)
#
#     # è®¡ç®—å¤´éƒ¨ä¸Šæ–¹çš„ç•™ç™½ï¼ˆç†æƒ³é«˜åº¦ä¸ºå¤´éƒ¨çš„20%-30%ï¼‰
#     # print("å¤´é¡¶é«˜åº¦:", get_highest_point(edge_frame, results))
#     head_height = abs(keypoints[0]['y'] - head_y)  # å¤´éƒ¨é«˜åº¦
#     head_margin = head_height * 0.4  # ç•™ç™½é«˜åº¦ï¼ˆå¤´éƒ¨é«˜åº¦çš„20%ï¼‰
#
#     # print(head_height, head_margin)
#     # åˆ¤æ–­å¤´éƒ¨æ˜¯å¦é è¿‘ç”»é¢é¡¶éƒ¨
#     if head_y < head_margin:
#         suggestions.append(
#             {"id": "ç•™ç™½", "text": "â¬† è¯·å‘ä¸Šç§»åŠ¨ä¸€ç‚¹ï¼ˆå¤´é¡¶ç©ºé—´ä¸è¶³ï¼‰", "need_modify": True}
#         )
#     # else:
#     #     suggestions.append(
#     #         {"id": "ç•™ç™½", "text": "âœ… å¤´é¡¶ç•™ç™½è¶³å¤Ÿ", "need_modify": False}
#     #     )
#
#
#     # if knee_y > 0.95:
#     if 1 > knee_left_y > 0.95 or 1 > knee_right_y > 0.95:
#         suggestions.append(
#             {"id": "å…³èŠ‚", "text": "â¬† è¯·å‘ä¸Šç§»åŠ¨ä¸€ç‚¹ï¼ˆè†ç›–éƒ¨åˆ†è¢«è£å‰ªï¼‰", "need_modify": True}
#         )
#     elif 1.02 > ankle_left_y > 0.95 or 1.02 > ankle_right_y > 0.95:
#         suggestions.append(
#             {"id": "å…³èŠ‚", "text": "â¬‡ è¯·å‘ä¸‹ç§»åŠ¨ä¸€ç‚¹ï¼ˆè„šè¸éƒ¨åˆ†è¢«è£å‰ªï¼‰", "need_modify": True}
#         )
#     # else:
#     #     suggestions.append(
#     #         {"id": "å…³èŠ‚", "text": "âœ… å…³èŠ‚å®Œæ•´æ˜¾ç¤º", "need_modify": False}
#     #     )
#
#     # åˆ¤æ–­èƒ³è†Šæ˜¯å¦å®Œå…¨å¯è§
#     # if 0.02<elbow_left_x<0.98 and 0.02<elbow_right_x<0.98:
#     #     suggestions.append(
#     #         {"id": "èƒ³è†Š", "text": "èƒ³è†Šå·²å®Œæ•´éœ²å‡ºï¼Œæ— éœ€è°ƒæ•´", "need_modify": False}
#     #     )
#     # else:
#     #     suggestions.append(
#     #         {"id": "èƒ³è†Š", "text": "å»ºè®®è°ƒæ•´ï¼Œèƒ³è†Šéƒ¨åˆ†ä¸å¯è§ï¼Œå¯èƒ½éœ€è¦ç¼©æ”¾æˆ–è°ƒæ•´è§’åº¦", "need_modify": True}
#     #     )
#     if elbow_left_x<0.02 and elbow_right_x>0.98:
#         suggestions.append(
#             {"id": "èƒ³è†Š", "text": "â¬†/â¬‡ ç¼©æ”¾ç”»é¢ï¼ˆä¸¤ä¾§èƒ³è†Šå‡éƒ¨åˆ†ä¸å¯è§ï¼‰", "need_modify": True}
#         )
#     elif elbow_left_x<0.02:
#         suggestions.append(
#             {"id": "èƒ³è†Š", "text": "â¬… è¯·å·¦ç§»ä¸€ç‚¹ï¼ˆå·¦ä¾§èƒ³è†Šä¸å¯è§ï¼‰", "need_modify": True}
#         )
#     elif elbow_right_x>0.98:
#         suggestions.append(
#             {"id": "èƒ³è†Š", "text": "â¡ è¯·å³ç§»ä¸€ç‚¹ï¼ˆå³ä¾§èƒ³è†Šä¸å¯è§ï¼‰", "need_modify": True}
#         )
#     # else:
#     #     suggestions.append(
#     #         {"id": "èƒ³è†Š", "text": "âœ… èƒ³è†Šå®Œæ•´æ˜¾ç¤º", "need_modify": False}
#     #     )
#
#     # åˆ¤æ–­äººç‰©æ˜¯å¦å±…ä¸­
#     center_x = width // 2
#     head_center_x = (keypoints[0]['x'] + keypoints[1]['x'] + keypoints[2]['x']) / 3
#     shoulder_center_x = (keypoints[1]['x'] + keypoints[2]['x']) / 2
#     person_center_x = (head_center_x + shoulder_center_x) / 2
#     # print(head_center_x, shoulder_center_x, person_center_x, center_x)
#     if abs(person_center_x - 0.5) > 0.1:
#         if person_center_x < 0.5:
#             suggestions.append(
#                 {"id": "ä¸­å¿ƒ", "text": "â¡ è¯·å³ç§»ä¸€ç‚¹ï¼ˆäººç‰©åå·¦ï¼‰", "need_modify": True}
#             )
#         else:
#             suggestions.append(
#                 {"id": "ä¸­å¿ƒ", "text": "â¬… è¯·å·¦ç§»ä¸€ç‚¹ï¼ˆäººç‰©åå³ï¼‰", "need_modify": True}
#             )
#     # else:
#     #     suggestions.append(
#     #         {"id": "ä¸­å¿ƒ", "text": "âœ… äººç‰©å±…ä¸­è‰¯å¥½", "need_modify": False}
#     #     )
#
#     # # åˆ¤æ–­æ˜¯å¦éœ€è¦ç¼©æ”¾ï¼ˆé€šè¿‡è‚©è†€å®½åº¦æ¥åˆ¤æ–­ï¼‰
#     # shoulder_width = abs(keypoints[1]['x'] - keypoints[2]['x'])  # è®¡ç®—è‚©è†€å®½åº¦
#     # zoom_suggestion = ""
#     # if shoulder_width < width * 0.2:
#     #     zoom_suggestion = "å»ºè®®æ”¾å¤§ï¼Œäººç‰©æ˜¾å¾—å¤ªå°"
#     # elif shoulder_width > width * 0.6:
#     #     zoom_suggestion = "å»ºè®®ç¼©å°ï¼Œäººç‰©å æ®ç©ºé—´è¿‡å¤§"
#     return suggestions

def analyze_crop_and_zoom(frame, keypoints, yolo_box):
    """
    æ™ºèƒ½æ‹ç…§æŒ‡å¯¼é€»è¾‘ï¼šæ£€æµ‹æ„å›¾ç¦å¿Œå¹¶ç»™å‡ºè°ƒæ•´å»ºè®®
    """
    suggestions = []
    h_img, w_img = frame.shape[:2]

    # 1. å®‰å…¨è§£åŒ… YOLO BBox (åƒç´ åæ ‡)
    if yolo_box is not None and len(yolo_box) == 4:
        # yolo_box æ ¼å¼: [x1, y1, x2, y2]
        y_x1, y_y1, y_x2, y_y2 = yolo_box
        # å½’ä¸€åŒ– YOLO åæ ‡ï¼Œæ–¹ä¾¿ä¸ 0.0-1.0 æ¯”è¾ƒ
        ny1, ny2 = y_y1 / h_img, y_y2 / h_img
        nx1, nx2 = y_x1 / w_img, y_x2 / w_img
    else:
        ny1 = ny2 = nx1 = nx2 = None

    # 2. è¾…åŠ©å‡½æ•°ï¼šå®‰å…¨è·å–å…³é”®ç‚¹
    def get_kp(idx):
        if idx < len(keypoints):
            return keypoints[idx]['x'], keypoints[idx]['y']
        return None, None

    # è·å–æ ¸å¿ƒç‚¹
    nose_x, nose_y = get_kp(0)
    lk_x, lk_y = get_kp(25)  # å·¦è†
    rk_x, rk_y = get_kp(26)  # å³è†
    la_x, la_y = get_kp(27)  # å·¦è¸
    ra_x, ra_y = get_kp(28)  # å³è¸

    # --- ç­–ç•¥ A: å¤´éƒ¨ç•™ç™½åˆ†æ ---
    # ä½¿ç”¨ YOLO çš„è¾¹ç•Œæ¡†é¡¶éƒ¨ä½œä¸ºâ€œå¤´é¡¶â€å‚è€ƒï¼ŒMediaPipe é¼»å­ä½œä¸ºå‚è€ƒç‚¹
    if ny1 is not None and nose_y is not None:
        head_height_norm = abs(nose_y - ny1)
        # ç†æƒ³ç•™ç™½ï¼šå¤´é¡¶ä¸Šæ–¹åº”ç•™å‡ºçº¦ 0.5 åˆ° 1.0 ä¸ªå¤´éƒ¨é«˜åº¦çš„ç©ºé—´
        if ny1 < 0.05:
            suggestions.append({"id": "ç•™ç™½", "text": "â¬† è¯·å‘ä¸Šç§»åŠ¨é•œå¤´ï¼ˆå¤´é¡¶å¿«å‡ºç•Œäº†ï¼‰", "need_modify": True})
        elif ny1 > 0.3:
            suggestions.append({"id": "ç•™ç™½", "text": "â¬‡ è¯·å‘ä¸‹ç§»åŠ¨é•œå¤´ï¼ˆå¤´é¡¶ç•™ç™½è¿‡å¤šï¼‰", "need_modify": True})

    # --- ç­–ç•¥ B: å…³èŠ‚è£å‰ªåˆ†æ (æ„å›¾å¤§å¿Œ) ---
    # æ‘„å½±åŸåˆ™ï¼šä¸è¦åœ¨å…³èŠ‚å¤„è£å‰ªã€‚å¦‚æœè†ç›–æˆ–è„šè¸åœ¨è¾¹ç¼˜ 5% èŒƒå›´å†…ï¼Œè§†ä¸ºè£å‰ªã€‚
    if lk_y is not None:
        max_knee_y = max(lk_y, rk_y)
        max_ankle_y = max(la_y, ra_y)

        if 0.92 < max_knee_y < 0.99:
            suggestions.append({"id": "å…³èŠ‚", "text": "â¬† è¯·ç¨å‘ä¸Šç§»ï¼ˆä¸è¦ä»è†ç›–å¤„æˆªæ–­ï¼‰", "need_modify": True})
        elif 0.92 < max_ankle_y < 0.99:
            suggestions.append({"id": "å…³èŠ‚", "text": "â¬‡ è¯·ç¨å‘ä¸‹ç§»ï¼ˆä¸è¦ä»è„šè¸å¤„æˆªæ–­ï¼‰", "need_modify": True})

    # --- ç­–ç•¥ C: èƒ³è†Šä¸æ¨ªå‘ç©ºé—´ ---
    if nx1 is not None:
        # æ£€æµ‹å·¦å³å‡ºç•Œ
        left_out = nx1 < 0.02
        right_out = nx2 > 0.98

        if left_out and right_out:
            suggestions.append({"id": "èƒ³è†Š", "text": "ğŸ” è¯·è¿œç¦»ä¸€ç‚¹ï¼ˆèº«ä½“ä¸¤ä¾§æ˜¾ç¤ºä¸å…¨ï¼‰", "need_modify": True})
        elif left_out:
            suggestions.append({"id": "èƒ³è†Š", "text": "â¬… è¯·å‘å·¦ç§»åŠ¨ï¼ˆå·¦è‡‚å‡ºç•Œï¼‰", "need_modify": True})
        elif right_out:
            suggestions.append({"id": "èƒ³è†Š", "text": "â¡ è¯·å‘å³ç§»åŠ¨ï¼ˆå³è‡‚å‡ºç•Œï¼‰", "need_modify": True})

    # --- ç­–ç•¥ D: é»„é‡‘åˆ†å‰²ä¸å±…ä¸­ ---
    if nose_x is not None:
        # è®¡ç®—èº¯å¹²ä¸­å¿ƒï¼ˆä»¥é¼»å­å’ŒåŒè‚©ä¸­å¿ƒä¸ºå‡†ï¼‰
        person_x_center = nose_x
        offset = person_x_center - 0.5  # åç¦»ä¸­å¿ƒçš„è·ç¦»

        if abs(offset) > 0.15:
            direction = "â¬… å·¦" if offset > 0 else "â¡ å³"
            suggestions.append({"id": "ä¸­å¿ƒ", "text": f"{direction} ç§»åŠ¨ä¸€ç‚¹ï¼ˆäººç‰©ä¸åœ¨ä¸­å¿ƒï¼‰", "need_modify": True})

    # --- ç­–ç•¥ E: å§¿åŠ¿è¯„åˆ†é€»è¾‘è¡¥å¿ ---
    # å¦‚æœæ²¡æœ‰ä»»ä½•ä¿®æ”¹å»ºè®®ï¼Œæ·»åŠ ä¸€ä¸ªæ­£é¢åé¦ˆ
    if not suggestions:
        suggestions.append({"id": "çŠ¶æ€", "text": "âœ… æ„å›¾å®Œç¾ï¼Œè¯·ä¿æŒ", "need_modify": False})

    return suggestions


def choose_scale(scale,
                 scale_candidates=(0.8, 0.9, 1.0, 1.2, 1.4, 1.6, 1.8, 2.0, 3.0),
                 threshold=0.95):
    """
    ä»å€™é€‰ç¼©æ”¾æ¯”ä¾‹ä¸­é€‰æ‹©åˆé€‚çš„å€¼ã€‚

    é€»è¾‘ï¼š
    1. æ‰¾åˆ°ä¸å¤§äº scale çš„æœ€å¤§å€™é€‰å€¼
    2. å¦‚æœæ‰¾ä¸åˆ°å°±å–æœ€å°å€™é€‰å€¼
    3. å¦‚æœæœ€ç»ˆç»“æœ >= threshold ä¸´è¿‘ 1ï¼Œåˆ™ç›´æ¥è¿”å› 1
    """
    # å–å°äºç­‰äº scale çš„å€™é€‰å€¼
    valid_scales = [s for s in scale_candidates if s <= scale]

    # é»˜è®¤é€‰å–
    selected = max(valid_scales) if valid_scales else min(scale_candidates)

    # å¦‚æœæ¥è¿‘ 1ï¼Œåˆ™ç›´æ¥è¿”å› 1
    if selected >= threshold:
        return 1.0

    return selected


def compute_bbox_by_mode(base_frame, keypoints, yolo_box, mode="å…¨èº«åƒ", target_aspect_ratio=None):
    h_img, w_img = base_frame.shape[:2]
    if target_aspect_ratio is None:
        target_aspect_ratio = w_img / h_img

    # --- 1. è·å–å…³é”®ç‚¹åƒç´ åæ ‡ ---
    mp_coords = []
    if keypoints:
        is_dict = isinstance(keypoints[0], dict)
        for kp in keypoints:
            kx = kp['x'] if is_dict else kp.x
            ky = kp['y'] if is_dict else kp.y
            mp_coords.append((kx * w_img, ky * h_img))

    # --- 2. æ„å›¾ä¸­å¿ƒä¸è¦†ç›–èŒƒå›´é…ç½® ---
    # æ ¼å¼: (ä¸­å¿ƒå‚è€ƒç‚¹ç´¢å¼•, è¦†ç›–èŒƒå›´å‚è€ƒçš„å…³é”®ç‚¹æ•°é‡, å‚ç›´ç¼©æ”¾å› å­)
    # å‚ç›´ç¼©æ”¾å› å­å†³å®šäº†ä»¥ä¸­å¿ƒç‚¹å‘æ•£å‡ºå»çš„è§†é‡å¤§å°
    comp_config = {
        "é¢éƒ¨ç‰¹å†™": {"anchor_idx": [0], "kp_count": 11, "v_scale": 1.5},  # ä»¥é¼»å­ä¸ºä¸­å¿ƒ
        "åŠèº«åƒ": {"anchor_idx": [11, 12], "kp_count": 25, "v_scale": 1.2},  # è‚©éƒ¨ä¸­ç‚¹(é”éª¨)
        "å…¨èº«åƒ": {"anchor_idx": [23, 24], "kp_count": 33, "v_scale": 1.1}  # èƒ¯éƒ¨ä¸­ç‚¹
    }

    cfg = comp_config.get(mode, comp_config["å…¨èº«åƒ"])

    # --- 3. è®¡ç®—ä¸­å¿ƒé”šç‚¹ (Target Center) ---
    if mp_coords:
        anchors = [mp_coords[i] for i in cfg["anchor_idx"] if i < len(mp_coords)]
        center_x = sum(a[0] for a in anchors) / len(anchors)
        center_y = sum(a[1] for a in anchors) / len(anchors)
    else:
        # å¦‚æœæ²¡ MP æ•°æ®ï¼Œé€€è€Œæ±‚å…¶æ¬¡ç”¨ YOLO ä¸­å¿ƒ
        if yolo_box:
            center_x = (yolo_box[0] + yolo_box[2]) / 2
            center_y = (yolo_box[1] + yolo_box[3]) / 2
        else:
            return {"mode": mode, "bbox": [0, 0, 1, 1], "scale": 1.0}  # å…œåº•

    # --- 4. è®¡ç®—è¦†ç›–èŒƒå›´ (BBox Size) ---
    # è·å–å¯¹åº”æ¨¡å¼çš„å…³é”®ç‚¹é›†ï¼Œè®¡ç®—ä¸€ä¸ªåŸºç¡€è·¨åº¦
    selected_kp = mp_coords[:cfg["kp_count"]] if mp_coords else []
    if selected_kp:
        xs, ys = zip(*selected_kp)
        raw_w = (max(xs) - min(xs)) * 1.5  # é€‚å½“å¢åŠ å®½åº¦ç•™ç™½
        raw_h = (max(ys) - min(ys)) * cfg["v_scale"]
    else:
        # åªæœ‰ YOLO æ¡†æ—¶çš„å¤„ç†
        raw_w = (yolo_box[2] - yolo_box[0]) if yolo_box else w_img
        raw_h = (yolo_box[3] - yolo_box[1]) if yolo_box else h_img

    # --- 5. æŒ‰ç…§ç›®æ ‡æ¯”ä¾‹é”å®šæœ€ç»ˆé•¿å®½ ---
    # ç¡®ä¿æ¡†ä¸ä¼šæ¯”ç›®æ ‡æ¯”ä¾‹çª„
    if raw_w / raw_h < target_aspect_ratio:
        final_h = raw_h
        final_w = final_h * target_aspect_ratio
    else:
        final_w = raw_w
        final_h = final_w / target_aspect_ratio

    # --- 6. ç”Ÿæˆæœ€ç»ˆè¾¹ç•Œå¹¶é˜²æ­¢è¶Šç•Œ ---
    f_x1 = max(0, center_x - final_w / 2)
    f_y1 = max(0, center_y - final_h / 2)
    f_x2 = min(w_img, f_x1 + final_w)
    f_y2 = min(h_img, f_y1 + final_h)

    # é‡æ–°ä¿®æ­£å› è¶Šç•Œå¯¼è‡´çš„ä½ç§»
    final_w = f_x2 - f_x1
    final_h = f_y2 - f_y1

    return {
        "mode": mode,
        "target_center": (round(center_x / w_img, 4), round(center_y / h_img, 4)),
        "bbox": [round(f_x1 / w_img, 4), round(f_y1 / h_img, 4), round(f_x2 / w_img, 4), round(f_y2 / h_img, 4)],
        "scale": round(h_img / final_h, 1) if final_h > 0 else 1.0
    }



# def compute_bbox_by_mode(base_frame, keypoints, yolo_box, mode="å…¨èº«åƒ", target_aspect_ratio=None):
#     """
#     æ™ºèƒ½æ„å›¾è®¡ç®—ï¼šç»“åˆ YOLO ç¨³å®šæ€§ä¸ MediaPipe ç²¾ç¡®åº¦
#     mode: "é¢éƒ¨ç‰¹å†™", "åŠèº«åƒ", "å…¨èº«åƒ"
#     """
#     # print(f"[æ„å›¾åˆ†æ] å½“å‰æ¨¡å¼: {mode}")
#     h_img, w_img = base_frame.shape[:2]
#
#     if target_aspect_ratio is None:
#         target_aspect_ratio = w_img / h_img
#
#     # --- 1. é¢„å¤„ç†ï¼šå®‰å…¨è·å–å…³é”®ç‚¹åƒç´ åæ ‡ ---
#     mp_coords = []
#     if keypoints:
#         try:
#             # è‡ªåŠ¨è¯†åˆ«æ˜¯å­—å…¸ kp['x'] è¿˜æ˜¯å¯¹è±¡ kp.x
#             is_dict = isinstance(keypoints[0], dict)
#             for kp in keypoints:
#                 kx = kp['x'] if is_dict else kp.x
#                 ky = kp['y'] if is_dict else kp.y
#                 mp_coords.append((kx * w_img, ky * h_img))
#         except Exception as e:
#             print(f"MediaPipe æ•°æ®è§£æå¼‚å¸¸: {e}")
#
#     # --- 2. æ¨¡å¼å‚æ•°é…ç½® (ç•™ç™½æ¯”ä¾‹) ---
#     # å®šä¹‰ï¼š(ä¸Šç•™ç™½, ä¸‹ç•™ç™½, å·¦å³ç•™ç™½)
#     config = {
#         "é¢éƒ¨ç‰¹å†™": (0.5, 0.3, 0.4, 11),  # å–å‰11ç‚¹
#         "åŠèº«åƒ": (0.2, 0.15, 0.2, 25),  # å–å‰25ç‚¹
#         "å…¨èº«åƒ": (0.1, 0.05, 0.1, 33)  # å…¨å–
#     }
#     pad_top, pad_bottom, pad_x, kp_count = config.get(mode, config["å…¨èº«åƒ"])
#
#     # --- 3. ç¡®å®šåŸå§‹è¾¹ç•Œ (MP ä¸ YOLO èåˆ) ---
#     selected_mp = mp_coords[:kp_count] if mp_coords else []
#
#     # åˆå§‹åŒ–è¾¹ç•Œä¸º None
#     mp_x1 = mp_y1 = mp_x2 = mp_y2 = None
#     if selected_mp:
#         xs, ys = zip(*selected_mp)
#         mp_x1, mp_y1, mp_x2, mp_y2 = min(xs), min(ys), max(xs), max(ys)
#
#     # å®‰å…¨å¤„ç† YOLO æ¡† (é˜²æ­¢ TypeError: cannot unpack non-iterable NoneType object)
#     y_x1 = y_y1 = y_x2 = y_y2 = None
#     if yolo_box is not None and len(yolo_box) == 4:
#         y_x1, y_y1, y_x2, y_y2 = yolo_box
#
#     # é€»è¾‘èåˆï¼š
#     # å¦‚æœæ˜¯é¢éƒ¨ç‰¹å†™ï¼Œå®Œå…¨ä¿¡ä»» MediaPipeï¼›å¦åˆ™å– MP å’Œ YOLO çš„å¹¶é›†å¢å¼ºç¨³å®šæ€§
#     if mode == "é¢éƒ¨ç‰¹å†™" or y_x1 is None:
#         f_x1, f_y1, f_x2, f_y2 = mp_x1, mp_y1, mp_x2, mp_y2
#     elif mp_x1 is None:
#         f_x1, f_y1, f_x2, f_y2 = y_x1, y_y1, y_x2, y_y2
#     else:
#         # èåˆï¼šå–ä¸¤è€…å¹¶é›†
#         f_x1 = min(mp_x1, y_x1)
#         f_y1 = min(mp_y1, y_y1)
#         f_x2 = max(mp_x2, y_x2)
#         f_y2 = max(mp_y2, y_y2)
#
#     # å…œåº•ï¼šå¦‚æœæ‰€æœ‰ç®—æ³•éƒ½æ²¡æŠ“åˆ°äººï¼Œè¿”å›å…¨å›¾
#     if f_x1 is None:
#         return {
#             "mode": mode,
#             "target_center": (0.5, 0.5),
#             "bbox": [0.0, 0.0, 1.0, 1.0],
#             "scale": 1.0
#         }
#
#     # --- 4. æ™ºèƒ½ç•™ç™½ä¸çºµæ¨ªæ¯”ä¿®æ­£ ---
#     box_w, box_h = f_x2 - f_x1, f_y2 - f_y1
#
#     # åº”ç”¨åˆå§‹è£å‰ªï¼ˆå¸¦ç•™ç™½ï¼‰
#     cx1 = max(0, f_x1 - box_w * pad_x)
#     cx2 = min(w_img, f_x2 + box_w * pad_x)
#     cy1 = max(0, f_y1 - box_h * pad_top)
#     cy2 = min(h_img, f_y2 + box_h * pad_bottom)
#
#     # çºµæ¨ªæ¯”é”å®šé€»è¾‘
#     curr_w, curr_h = cx2 - cx1, cy2 - cy1
#     curr_ratio = curr_w / curr_h
#
#     if curr_ratio < target_aspect_ratio:
#         # å¤ªç˜¦äº†ï¼Œè¡¥å®½åº¦
#         needed_w = curr_h * target_aspect_ratio
#         diff = needed_w - curr_w
#         cx1 -= diff / 2
#         cx2 += diff / 2
#     else:
#         # å¤ªèƒ–äº†ï¼Œè¡¥é«˜åº¦
#         needed_h = curr_w / target_aspect_ratio
#         diff = needed_h - curr_h
#         cy1 -= diff / 2
#         cy2 += diff / 2
#
#     # æœ€ç»ˆåƒç´ åæ ‡
#     final_x1, final_y1 = max(0, cx1), max(0, cy1)
#     final_x2, final_y2 = min(w_img, cx2), min(h_img, cy2)
#
#     # --- 6. æ„é€ å“åº”ç»“æ„ ---
#     final_w = final_x2 - final_x1
#     final_h = final_y2 - final_y1
#
#     # è®¡ç®—ç›¸å¯¹äºåŸå›¾çš„ç¼©æ”¾å€ç‡
#     scale = round(h_img / final_h, 1) if final_h > 0 else 1.0
#
#     return {
#         "mode": mode,
#         "target_center": (round((final_x1 + final_w / 2) / w_img, 4), round((final_y1 + final_h / 2) / h_img, 4)),
#         "bbox": [
#             round(final_x1 / w_img, 4),
#             round(final_y1 / h_img, 4),
#             round(final_x2 / w_img, 4),
#             round(final_y2 / h_img, 4)
#         ],
#         "scale": scale,
#     }



# def compute_bbox(base_frame, keypoints, model):
#     """
#     æ ¹æ®ç°æœ‰ analyze_crop_and_zoom è§„åˆ™
#     è¿”å›ï¼šæ–°çš„ç›®æ ‡ä¸­å¿ƒç‚¹ (cx, cy)ï¼Œnormalized åæ ‡
#     """
#     frame = base_frame.copy()
#
#     height, width = frame.shape[:2]
#
#     # ========= åŸå§‹äººç‰©ä¸­å¿ƒ =========
#     head_center_x = (keypoints[mp_pose.PoseLandmark.LEFT_EYE]['x'] + keypoints[mp_pose.PoseLandmark.RIGHT_EYE]['x']) / 2
#     shoulder_center_x = (keypoints[mp_pose.PoseLandmark.LEFT_SHOULDER]['x'] + keypoints[mp_pose.PoseLandmark.RIGHT_SHOULDER]['x']) / 2
#
#     person_center_x = (head_center_x + shoulder_center_x) / 2
#
#     person_center_y = (
#         float(keypoints[mp_pose.PoseLandmark.LEFT_SHOULDER]['y']) +
#         float(keypoints[mp_pose.PoseLandmark.RIGHT_SHOULDER]['y'])
#     ) / 2
#
#     # åˆå§‹åŒ–åç§»
#     dx = 0.0
#
#     # ========= 1ï¸âƒ£ å¤´éƒ¨ç•™ç™½ =========
#     edge_frame = mask_hip_below(frame, keypoints)
#     results = model(cv2.cvtColor(edge_frame, cv2.COLOR_BGR2RGB))
#     head_y = get_highest_point(edge_frame, results)
#     elbow_left_x, elbow_right_x = get_edge_point(frame, results)
#
#     head_height = abs(keypoints[0]['y'] - head_y)  # å¤´éƒ¨é«˜åº¦
#     head_margin = head_height * 0.4
#
#     highest = head_y - head_margin
#
#     # ========= 2ï¸âƒ£ è†ç›– / è„šè¸ =========
#     knee_left_y = keypoints[25]['y']
#     knee_right_y = keypoints[26]['y']
#     # ankle_left_y = keypoints[27]['y']
#     # ankle_right_y = keypoints[28]['y']
#     ankle_y = (keypoints[mp_pose.PoseLandmark.LEFT_ANKLE]['y'] + keypoints[mp_pose.PoseLandmark.RIGHT_ANKLE]['y']) / 2
#     hip_y = (keypoints[mp_pose.PoseLandmark.LEFT_HIP]['y'] + keypoints[mp_pose.PoseLandmark.RIGHT_HIP]['y']) / 2
#
#
#     lowest = 1
#     if 1 > knee_left_y > 0.95 or 1 > knee_right_y > 0.95:
#         # è†ç›–è¢«è£ â†’ äººæ•´ä½“ä¸Šç§»
#         lowest = (ankle_y + hip_y) / 2
#         # dy -= 0.06
#     elif 1.02 > ankle_y > 0.95:
#         # è„šè¸è¢«è£ â†’ äººæ•´ä½“ä¸‹ç§»
#         # dy += 0.06
#         lowest = ankle_y + 0.1
#     # ========= 3ï¸âƒ£ èƒ³è†Šå·¦å³è£åˆ‡ =========
#     elbow_left_x, elbow_right_x = get_edge_point(frame, results)
#
#     if elbow_left_x < 0.02 and elbow_right_x > 0.98:
#         pass  # è¿™æ˜¯ç¼©æ”¾é—®é¢˜ï¼Œä¸åŠ¨ä¸­å¿ƒ
#     elif elbow_left_x < 0.02:
#         dx += 0.05
#     elif elbow_right_x > 0.98:
#         dx -= 0.05
#
#     # ========= 4ï¸âƒ£ äººç‰©å±…ä¸­ =========
#     if abs(person_center_x - 0.5) > 0.1:
#         dx += (0.5 - person_center_x) * 0.5
#
#
#     # highest = min(highest,lowest - (elbow_right_x - elbow_left_x + 0.05) * height / width)
#     # ========= åˆæˆæ–°ä¸­å¿ƒ =========
#     new_center_x = np.clip(person_center_x + dx, 0.1, 0.9)
#     # print(highest, lowest)
#     new_center_y = (highest + lowest)/2
#
#     person_center_x *= width
#     person_center_y *= height
#     new_center_x *= width
#     new_center_y *= height
#
#
#     scale = choose_scale(lowest - highest)
#     bbox_h = height / scale
#     bbox_w = width / scale
#
#     x1 = new_center_x - bbox_w / 2
#     y1 = new_center_y - bbox_h / 2
#     x2 = new_center_x + bbox_w / 2
#     y2 = new_center_y + bbox_h / 2
#
#     # è£å‰ªé˜²æ­¢è¶Šç•Œ
#     x1, y1 = max(0, x1), max(0, y1)
#     x2, y2 = min(width, x2), min(height, y2)
#
#     return {
#         "target_center": (new_center_x, new_center_y),
#         "bbox":(x1, y1, x2, y2),
#         "scale": scale,
#     }



def compute_bbox(base_frame, keypoints, model, target_aspect_ratio=None):
    """
    ç»“åˆ YOLOv5s (è¾¹ç•Œå‡†ç¡®) å’Œ MediaPipe (å§¿æ€å‡†ç¡®) çš„è£åˆ‡é€»è¾‘ã€‚
    ä¼˜å…ˆä¿è¯ï¼šè‚¢ä½“å®Œæ•´æ€§ (èƒ³è†Šã€è†ç›–ã€è„šè¸ä¸è¢«åˆ‡)ã€‚
    """
    frame = base_frame.copy()
    h_img, w_img = frame.shape[:2]

    # é»˜è®¤ä¿æŒåŸå›¾æ¯”ä¾‹ï¼Œæˆ–è€…æŒ‡å®šå¦‚ 9/16, 16/9
    if target_aspect_ratio is None:
        target_aspect_ratio = w_img / h_img

    # ================= 1. è·å– MediaPipe çš„æé™è¾¹ç•Œ =================
    # åŒ…å«äº†æ‰‹è…•ã€è„šè¸ã€è†ç›–çš„æ‰€æœ‰ç‚¹
    mp_x1, mp_y1, mp_x2, mp_y2 = _get_mediapipe_bbox(keypoints, w_img, h_img)

    # ================= 2. è·å– YOLOv5 çš„æ£€æµ‹è¾¹ç•Œ =================
    # YOLO çœ‹åˆ°çš„é€šå¸¸æ¯” MediaPipe æ›´â€œèƒ–â€ä¸€äº›ï¼ˆåŒ…å«è¡£æœï¼‰
    yolo_x1, yolo_y1, yolo_x2, yolo_y2 = _get_yolo_bbox(model, frame)

    # ================= 3. è®¡ç®—â€œå¹¶é›†â€ (Union Box) =================
    # å–ä¸¤è€…æœ€å®½çš„èŒƒå›´ï¼Œç¡®ä¿ç»å¯¹ä¸åˆ‡æ‰‹ã€ä¸åˆ‡è„š
    # å¦‚æœ YOLO æ²¡æ£€æµ‹åˆ°äººï¼Œå°±å®Œå…¨ä¿¡èµ– MediaPipe
    if yolo_x1 is None:
        final_x1, final_y1, final_x2, final_y2 = mp_x1, mp_y1, mp_x2, mp_y2
    else:
        final_x1 = min(mp_x1, yolo_x1)
        final_y1 = min(mp_y1, yolo_y1)
        final_x2 = max(mp_x2, yolo_x2)
        final_y2 = max(mp_y2, yolo_y2)

    # ================= 4. æ™ºèƒ½ç•™ç™½ (Padding) =================
    # æ—¢ç„¶ç›®æ ‡æ˜¯â€œå®Œæ•´å±•ç¤ºâ€ï¼Œæˆ‘ä»¬éœ€è¦åœ¨æå€¼è¾¹ç•Œå¤–å†åŠ ä¸€ç‚¹ buffer
    box_h = final_y2 - final_y1

    # é¡¶éƒ¨ç•™ç™½ï¼šé˜²æ­¢å¤´é¡¶å¤ªè´´è¾¹ (Headroom)
    pad_top = box_h * 0.15
    # åº•éƒ¨ç•™ç™½ï¼šé˜²æ­¢è„šåº•å¤ªè´´è¾¹
    pad_bottom = box_h * 0.05
    # å·¦å³ç•™ç™½ï¼šé˜²æ­¢æŒ¥æ‰‹æ—¶æ‰‹æŒ‡è´´è¾¹
    pad_x = (final_x2 - final_x1) * 0.1

    # åº”ç”¨ç•™ç™½
    crop_x1 = max(0, final_x1 - pad_x)
    crop_x2 = min(w_img, final_x2 + pad_x)
    crop_y1 = max(0, final_y1 - pad_top)
    crop_y2 = min(h_img, final_y2 + pad_bottom)

    # ================= 5. ä¿®æ­£çºµæ¨ªæ¯” (Aspect Ratio Fit) =================
    # ç°åœ¨çš„ box ä»…ä»…æ˜¯åŒ…è£¹ä½äº†äººï¼Œå¯èƒ½æ¯”ä¾‹å¾ˆå¥‡æ€ªï¼ˆæ¯”å¦‚ç»†é•¿æ¡ï¼‰
    # æˆ‘ä»¬éœ€è¦å‘å¤–æ‰©å±•èƒŒæ™¯ï¼Œç›´åˆ°ç¬¦åˆ target_aspect_ratio

    current_w = crop_x2 - crop_x1
    current_h = crop_y2 - crop_y1
    current_ratio = current_w / current_h

    # ç›®æ ‡ä¸­å¿ƒç‚¹ï¼ˆä»¥æ­¤ä¸ºåŸºå‡†å‘å¤–æ‰©ï¼‰
    # è¿™é‡Œåšä¸€ä¸ªå¾®è°ƒï¼šä¸­å¿ƒç‚¹ç¨å¾®ä¸Šç§»ä¸€ç‚¹ç‚¹ï¼Œè§†è§‰ä¸Šæ›´ç¨³ï¼ˆèƒ¸å£ä½ç½®ï¼‰ï¼Œè€Œä¸æ˜¯å‡ ä½•ä¸­å¿ƒï¼ˆè‚šè„ï¼‰
    cx = (crop_x1 + crop_x2) / 2
    cy = (crop_y1 + crop_y2) / 2

    if current_ratio < target_aspect_ratio:
        # å½“å‰å¤ªç˜¦ -> å¢åŠ å®½åº¦
        target_w = current_h * target_aspect_ratio
        delta_w = target_w - current_w
        crop_x1 -= delta_w / 2
        crop_x2 += delta_w / 2
    else:
        # å½“å‰å¤ªèƒ– -> å¢åŠ é«˜åº¦
        target_h = current_w / target_aspect_ratio
        delta_h = target_h - current_h
        crop_y1 -= delta_h / 2
        crop_y2 += delta_h / 2

    # ================= 6. æœ€ç»ˆè¾¹ç•Œå¤„ç† (Shift & Clip) =================
    # å¦‚æœå‘å¤–æ‰©å……æ—¶è¶…å‡ºäº†å›¾ç‰‡è¾¹ç•Œï¼Œæˆ‘ä»¬éœ€è¦å¹³ç§»æ¡†ï¼Œå°½é‡ä¸è¦ç¼©å°æ¡†

    # æ£€æŸ¥å·¦ç•Œ
    if crop_x1 < 0:
        crop_x2 += abs(crop_x1)  # å¾€å³æ¨
        crop_x1 = 0
    # æ£€æŸ¥å³ç•Œ
    if crop_x2 > w_img:
        crop_x1 -= (crop_x2 - w_img)  # å¾€å·¦æ¨
        crop_x2 = w_img

    # æ£€æŸ¥ä¸Šç•Œ
    if crop_y1 < 0:
        crop_y2 += abs(crop_y1)
        crop_y1 = 0
    # æ£€æŸ¥ä¸‹ç•Œ
    if crop_y2 > h_img:
        crop_y1 -= (crop_y2 - h_img)
        crop_y2 = h_img

    # æœ€åçš„å®‰å…¨æˆªæ–­ï¼ˆé˜²æ­¢å¹³ç§»åè¿˜ä¸å¤Ÿï¼‰
    x1, y1 = max(0, crop_x1), max(0, crop_y1)
    x2, y2 = min(w_img, crop_x2), min(h_img, crop_y2)

    # è®¡ç®—æœ€ç»ˆä¸­å¿ƒå’Œ Scale
    final_cx = (x1 + x2) / 2
    final_cy = (y1 + y2) / 2

    # Scale å®šä¹‰ï¼šåŸå›¾é«˜åº¦ / è£åˆ‡æ¡†é«˜åº¦
    # æ„å‘³ç€å¦‚æœåªæˆªå–äº†ä¸€åŠç”»é¢ï¼Œç”»é¢å°±æ”¾å¤§äº†2å€
    # scale = h_img / (y2 - y1) if (y2 - y1) > 0 else 1.0
    scale = round(h_img / (y2 - y1) if (y2 - y1) > 0 else 1.0, 1)

    return {
        "target_center": (final_cx, final_cy),
        "bbox": (int(x1), int(y1), int(x2), int(y2)),
        "scale": scale,
    }


def compute_bbox_standard(base_frame, keypoints, model, target_aspect_ratio=None):
    """
    ç»“åˆ YOLOv5s å’Œ MediaPipe çš„è£åˆ‡é€»è¾‘ã€‚
    è¾“å‡ºï¼šå½’ä¸€åŒ–åçš„åæ ‡ (0.0 - 1.0)
    """
    frame = base_frame.copy()
    h_img, w_img = frame.shape[:2]

    if target_aspect_ratio is None:
        target_aspect_ratio = w_img / h_img

    # 1. è·å–è¾¹ç•Œ (åŸå§‹åƒç´ åæ ‡)
    mp_x1, mp_y1, mp_x2, mp_y2 = _get_mediapipe_bbox(keypoints, w_img, h_img)
    yolo_x1, yolo_y1, yolo_x2, yolo_y2 = _get_yolo_bbox_by_results(model)

    # 2. è®¡ç®—å¹¶é›†
    if yolo_x1 is None:
        final_x1, final_y1, final_x2, final_y2 = mp_x1, mp_y1, mp_x2, mp_y2
    else:
        final_x1, final_y1 = min(mp_x1, yolo_x1), min(mp_y1, yolo_y1)
        final_x2, final_y2 = max(mp_x2, yolo_x2), max(mp_y2, yolo_y2)

    # 3. æ™ºèƒ½ç•™ç™½
    box_h = final_y2 - final_y1
    pad_top, pad_bottom = box_h * 0.15, box_h * 0.05
    pad_x = (final_x2 - final_x1) * 0.1

    crop_x1, crop_x2 = max(0, final_x1 - pad_x), min(w_img, final_x2 + pad_x)
    crop_y1, crop_y2 = max(0, final_y1 - pad_top), min(h_img, final_y2 + pad_bottom)

    # 4. ä¿®æ­£çºµæ¨ªæ¯”
    current_w, current_h = crop_x2 - crop_x1, crop_y2 - crop_y1
    current_ratio = current_w / current_h

    if current_ratio < target_aspect_ratio:
        target_w = current_h * target_aspect_ratio
        delta_w = target_w - current_w
        crop_x1 -= delta_w / 2
        crop_x2 += delta_w / 2
    else:
        target_h = current_w / target_aspect_ratio
        delta_h = target_h - current_h
        crop_y1 -= delta_h / 2
        crop_y2 += delta_h / 2

    # 5. è¾¹ç•Œå¹³ç§»ä¸æˆªæ–­ (Shift & Clip)
    if crop_x1 < 0:
        crop_x2 += abs(crop_x1)
        crop_x1 = 0
    if crop_x2 > w_img:
        crop_x1 -= (crop_x2 - w_img);
        crop_x2 = w_img
    if crop_y1 < 0:
        crop_y2 += abs(crop_y1);
        crop_y1 = 0
    if crop_y2 > h_img:
        crop_y1 -= (crop_y2 - h_img);
        crop_y2 = h_img

    x1, y1 = max(0, crop_x1), max(0, crop_y1)
    x2, y2 = min(w_img, crop_x2), min(h_img, crop_y2)

    # 6. è®¡ç®—æœ€ç»ˆä¸­å¿ƒ (åƒç´ )
    final_cx = (x1 + x2) / 2
    final_cy = (y1 + y2) / 2

    # 7. è®¡ç®—ç¼©æ”¾å€æ•°
    scale = round(h_img / (y2 - y1) if (y2 - y1) > 0 else 1.0, 1)

    # ================= å½’ä¸€åŒ–å¤„ç† =================
    return {
        # ä¸­å¿ƒç‚¹åæ ‡ (x/w, y/h)
        "target_center": (round(final_cx / w_img, 4), round(final_cy / h_img, 4)),

        # è¾¹ç•Œæ¡† [x1/w, y1/h, x2/w, y2/h]
        "bbox": [
            round(x1 / w_img, 4),
            round(y1 / h_img, 4),
            round(x2 / w_img, 4),
            round(y2 / h_img, 4)
        ],

        # Scale æ˜¯æ¯”ä¾‹å€¼ï¼Œæœ¬èº«å°±æ˜¯å½’ä¸€åŒ–çš„ï¼Œæ— éœ€é™¤ä»¥å®½é«˜
        "scale": scale,
    }


def _get_mediapipe_bbox(keypoints, w, h):
    """ä»å…³é”®ç‚¹è·å–ç»å¯¹åæ ‡çš„ bbox"""
    # ç­›é€‰å…¨èº«å…³é”®ç‚¹ (ä¸ä»…æ˜¯å¤´è‚©ï¼Œè¿˜æœ‰å››è‚¢)
    # MediaPipe Pose landmarks:
    # 11-12: Shoulders, 13-14: Elbows, 15-16: Wrists
    # 23-24: Hips, 25-26: Knees, 27-28: Ankles, 29-30: Heels, 31-32: Foot index
    indices = [0, 11, 12, 13, 14, 15, 16, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]

    xs = []
    ys = []
    for idx in indices:
        kp = keypoints[idx]
        # åªè¦å¯è§æ€§å¤§äº 0.5 æˆ–è€… x,y ä¸ä¸º 0
        if kp.get('visibility', 1.0) > 0.3:
            xs.append(kp['x'])
            ys.append(kp['y'])

    if not xs:
        return 0, 0, w, h  # Fallback

    min_x, max_x = min(xs) * w, max(xs) * w
    min_y, max_y = min(ys) * h, max(ys) * h
    return min_x, max_y, max_x, max_y  # æ³¨æ„è¿™é‡Œæœ‰ç‚¹ç¬”è¯¯ï¼Œä¿®æ­£å¦‚ä¸‹:
    return min_x, min_y, max_x, max_y


def _get_yolo_bbox(model, frame):
    """è¿è¡Œ YOLOv5s è·å–æœ€å¤§çš„äººä½“ Box"""
    # è½¬ RGB
    img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

    # æ¨ç†
    results = model(img_rgb)

    # è§£æç»“æœï¼špandas format æ¯”è¾ƒå¥½å¤„ç†
    df = results.pandas().xyxy[0]

    # ç­›é€‰ç±»åˆ« (class 0 é€šå¸¸æ˜¯ person, å…·ä½“çœ‹ä½ çš„æ¨¡å‹é…ç½®)
    people = df[df['class'] == 0]

    if people.empty:
        return None, None, None, None

    # æ‰¾åˆ°ç½®ä¿¡åº¦æœ€é«˜ï¼Œæˆ–è€…é¢ç§¯æœ€å¤§çš„äºº
    # è¿™é‡Œå‡è®¾ç”»é¢ä¸»ä½“æ˜¯é¢ç§¯æœ€å¤§çš„äºº
    people['area'] = (people['xmax'] - people['xmin']) * (people['ymax'] - people['ymin'])
    target = people.loc[people['area'].idxmax()]

    return target['xmin'], target['ymin'], target['xmax'], target['ymax']


def _get_yolo_bbox_by_results(results):
    """è¿è¡Œ YOLOv5s è·å–æœ€å¤§çš„äººä½“ Box"""


    # è§£æç»“æœï¼špandas format æ¯”è¾ƒå¥½å¤„ç†
    df = results.pandas().xyxy[0]

    # ç­›é€‰ç±»åˆ« (class 0 é€šå¸¸æ˜¯ person, å…·ä½“çœ‹ä½ çš„æ¨¡å‹é…ç½®)
    people = df[df['class'] == 0]

    if people.empty:
        return None, None, None, None

    # æ‰¾åˆ°ç½®ä¿¡åº¦æœ€é«˜ï¼Œæˆ–è€…é¢ç§¯æœ€å¤§çš„äºº
    # è¿™é‡Œå‡è®¾ç”»é¢ä¸»ä½“æ˜¯é¢ç§¯æœ€å¤§çš„äºº
    people['area'] = (people['xmax'] - people['xmin']) * (people['ymax'] - people['ymin'])
    target = people.loc[people['area'].idxmax()]

    return target['xmin'], target['ymin'], target['xmax'], target['ymax']
def get_keypoints_bbox(keypoints, ids):
    xs, ys = [], []

    for i in ids:
        kp = keypoints.get(i)
        if kp and kp["visibility"] > 0.5:
            xs.append(kp["x"])
            ys.append(kp["y"])

    if not xs:
        return None

    return {
        "x_min": min(xs),
        "x_max": max(xs),
        "y_min": min(ys),
        "y_max": max(ys)
    }

def apply_head_margin(bbox, keypoints):
    head_y = keypoints[0]["y"]
    shoulder_y = (keypoints[11]["y"] + keypoints[12]["y"]) / 2
    head_height = abs(shoulder_y - head_y)

    head_margin = head_height * 0.4

    bbox["y_min"] = min(bbox["y_min"], head_y - head_margin)
    return bbox

def expand_bbox_to_target_ratio(bbox, target_body_ratio=0.9):
    """
    target_body_ratio: äººä½“é«˜åº¦ / ç”»é¢é«˜åº¦
    """
    body_height = bbox["y_max"] - bbox["y_min"]

    target_frame_height = body_height / target_body_ratio
    extra = target_frame_height - body_height

    bbox["y_min"] -= extra * 0.5
    bbox["y_max"] += extra * 0.5

    return bbox

def compute_zoom_from_bbox(bbox):
    """
    è¿”å› zoom å€¼ï¼ˆ>1 è¡¨ç¤ºæ”¾å¤§ï¼‰
    """
    bbox_height = bbox["y_max"] - bbox["y_min"]
    zoom = 1.0 / bbox_height
    return np.clip(zoom, 1.0, 2.5)


def compute_target_zoom(frame, keypoints, model):
    edge_frame = mask_hip_below(frame, keypoints)
    # BGR è½¬ RGB
    img_rgb = cv2.cvtColor(edge_frame, cv2.COLOR_BGR2RGB)

    # è¿›è¡Œæ¨ç†
    results = model(img_rgb)

    bbox = get_box(edge_frame, results)

    if bbox is None:
        return 1.0

    bbox = apply_head_margin(bbox, keypoints)
    bbox = expand_bbox_to_target_ratio(bbox, target_body_ratio=0.9)

    zoom = compute_zoom_from_bbox(bbox)
    return zoom

def compute_bbox_from_center_and_scale(
    image_shape,
    center_x,
    center_y,
    scale,
    aspect_ratio=0.5,
    normalized=True
):
    """
    image_shape: (H, W, C)
    center_x, center_y: ä¸­å¿ƒç‚¹ï¼ˆå½’ä¸€åŒ–æˆ–åƒç´ ï¼‰
    scale: ç›¸å¯¹äºå›¾åƒé«˜åº¦çš„æ¯”ä¾‹
    aspect_ratio: w / h
    normalized: æ˜¯å¦æ˜¯å½’ä¸€åŒ–åæ ‡
    """

    height, width = image_shape[:2]

    # ä¸­å¿ƒç‚¹ â†’ åƒç´ 
    if normalized:
        cx = center_x * width
        cy = center_y * height
    else:
        cx, cy = center_x, center_y

    box_h = height * scale
    box_w = box_h * aspect_ratio

    x1 = int(max(0, cx - box_w / 2))
    y1 = int(max(0, cy - box_h / 2))
    x2 = int(min(width,  cx + box_w / 2))
    y2 = int(min(height, cy + box_h / 2))

    return x1, y1, x2, y2, int(cx), int(cy)


def get_center_point(keypoints):
    """
    æ ¹æ®å…³é”®ç‚¹è®¡ç®—äººç‰©çš„ä¸­å¿ƒç‚¹ã€‚è¿™é‡Œå–çš„æ˜¯å¤´éƒ¨ã€è‚©è†€å’Œè‡€éƒ¨çš„ä¸­é—´ç‚¹
    """
    head_center_x = (keypoints[0]['x'] + keypoints[1]['x'] + keypoints[2]['x']) / 3
    shoulder_center_x = (keypoints[1]['x'] + keypoints[2]['x']) / 2
    # è®¡ç®—äººç‰©çš„æ°´å¹³ä¸­å¿ƒç‚¹
    person_center_x = (head_center_x + shoulder_center_x) / 2
    # è®¡ç®—äººç‰©çš„å‚ç›´ä¸­å¿ƒç‚¹ï¼ˆè¿™é‡Œå¯ä»¥æ ¹æ®å¤´éƒ¨ã€è‚©è†€å’Œé«‹éƒ¨çš„yåæ ‡å¹³å‡å€¼æ¥ç¡®å®šï¼‰
    person_center_y = (keypoints[0]['y'] + keypoints[1]['y'] + keypoints[2]['y'] + keypoints[25]['y'] + keypoints[26]['y']) / 5
    return person_center_x, person_center_y



def get_result(frame, keypoints):
    """
    æ ¹æ®å…³é”®ç‚¹è®¡ç®—ç›®æ ‡çŸ©å½¢æ¡†çš„ä½ç½®å’Œå¤§å°ï¼Œå¹¶è¿”å›è°ƒæ•´åçš„çŸ©å½¢æ¡†
    """
    height, width = frame.shape[:2]

    # è·å–å½“å‰çš„ä¸­å¿ƒç‚¹
    person_center_x, person_center_y = get_center_point(keypoints)

    # å›¾åƒä¸­å¿ƒç‚¹
    center_x = width // 2
    center_y = height // 2

    # è®¡ç®—åç§»é‡
    offset_x = center_x - person_center_x * width
    offset_y = center_y - person_center_y * height

    # è®¡ç®—ç†æƒ³çš„çŸ©å½¢æ¡†å¤§å°ï¼ˆä¾‹å¦‚ï¼ŒåŸºäºè†ç›–å’Œè‚©è†€çš„è·ç¦»æ¥ä¼°ç®—ï¼‰
    shoulder_width = abs(keypoints[1]['x'] - keypoints[2]['x']) * width
    height_margin = abs(keypoints[0]['y'] - keypoints[25]['y']) * height  # èº«ä½“çš„å‚ç›´é«˜åº¦ï¼ˆä»å¤´åˆ°è†ç›–ï¼‰

    # è®¡ç®—çŸ©å½¢æ¡†çš„å·¦ä¸Šè§’å’Œå³ä¸‹è§’
    left = int(max(0, offset_x))
    top = int(max(0, offset_y))
    right = int(min(width, left + shoulder_width))
    bottom = int(min(height, top + height_margin))

    return left, top, right, bottom


def suggest_orientation_multi(yolo_results, target_aspect_ratio=None):
    """
    æ ¹æ® YOLO æ£€æµ‹åˆ°çš„æ‰€æœ‰äººï¼Œåˆ¤æ–­æ•´ä½“é€‚åˆæ¨ªå±è¿˜æ˜¯ç«–å±ã€‚

    Args:
        yolo_results: YOLOv5 çš„ pandas ç»“æœ (df = results.pandas().xyxy[0])
    """
    # ç­›é€‰æ‰€æœ‰äºº
    people = yolo_results[0]

    if len(people) == 0:
        return "Portrait", "æœªæ£€æµ‹åˆ°äººç‰©"

    # 1. è®¡ç®—æ‰€æœ‰äººæ„æˆçš„â€œå¤§åŒ…å›´ç›’â€
    all_x1 = people['xmin'].min()
    all_y1 = people['ymin'].min()
    all_x2 = people['xmax'].max()
    all_y2 = people['ymax'].max()

    group_w = all_x2 - all_x1
    group_h = all_y2 - all_y1
    group_ratio = group_w / group_h  # æ³¨æ„è¿™é‡Œç”¨ W/Hï¼Œå¤§äº 1 è¡¨ç¤ºå®½

    # 2. å†³ç­–é€»è¾‘
    if len(people) == 1:
        # å•äººæƒ…å†µï¼šå›å½’å§¿æ€é€»è¾‘ï¼ˆæ­¤å¤„ç®€åŒ–ä¸ºæ¯”ä¾‹åˆ¤æ–­ï¼‰
        return "Portrait" if group_ratio < 0.8 else "Landscape", "å•äººå§¿æ€é€‚é…"

    # 3. å¤šäººæ ¸å¿ƒé€»è¾‘
    if len(people) >= 2:
        # å¦‚æœäººç¾¤å®½åº¦æ˜æ˜¾å¤§äºé«˜åº¦ (ä¾‹å¦‚ 2 äººå¹¶æ’ï¼Œæ¯”ä¾‹é€šå¸¸ä¼šè¶…è¿‡ 1.2)
        if group_ratio > 1.2:
            return "Landscape", f"æ£€æµ‹åˆ° {len(people)} äººæ¨ªå‘æ’å¸ƒï¼Œå»ºè®®æ¨ªå±æ•æ‰å…¨å‘˜"

        # å¦‚æœäººç¾¤æ¯”è¾ƒâ€œç˜¦é•¿â€ï¼ˆä¾‹å¦‚å‰åç«™ä½æˆ–æ‹¥æŠ±ï¼‰
        elif group_ratio < 0.85:
            return "Portrait", "äººç¾¤æ„å›¾ç´§å‡‘ï¼Œç«–å±æ›´å…·è§†è§‰é‡å¿ƒ"

        # å¤„äºä¸­é—´åœ°å¸¦ (0.85 ~ 1.2)
        else:
            return "Landscape", "å¤šäººç»„åˆæ„å›¾ï¼Œå»ºè®®ä½¿ç”¨æ¨ªå±é¢„ç•™ç¯å¢ƒç©ºé—´"