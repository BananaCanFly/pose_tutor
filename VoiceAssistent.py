# VoiceAssistant.py
import queue
import json
import time
import threading

import numpy as np
import sounddevice as sd
from vosk import Model, KaldiRecognizer
import pyttsx3


class VoiceAssistant:
    def __init__(
        self,
        model_path: str,
        get_suggestion_func,
        sample_rate: int = 16000,
        cooldown: float = 5.0,
    ):
        """
        model_path: vosk æ¨¡å‹è·¯å¾„
        get_suggestion_func: å›è°ƒå‡½æ•°ï¼Œè¿”å›å½“å‰ã€Œä¸»è¦å§¿åŠ¿å»ºè®®ã€
        cooldown: ä¸¤æ¬¡æ’­æŠ¥æœ€å°é—´éš”ï¼ˆç§’ï¼‰
        """
        self.model_path = model_path
        self.sample_rate = sample_rate
        self.cooldown = cooldown
        self.get_suggestion = get_suggestion_func

        self.q = queue.Queue()
        self.last_speak_time = 0
        self.running = False

        self.tts_queue = queue.Queue()
        self.tts_lock = threading.Lock()

        # å…³é”®è¯ï¼ˆä½ å¯ä»¥éšæ—¶æ”¹ï¼‰
        self.trigger_words = [
            "å»ºè®®",
            "å§¿åŠ¿",
            "æ€ä¹ˆ",
            "è°ƒæ•´",
            "æˆ‘è¯¥",
            "ç°åœ¨",
        ]

        # TTS
        self.engine = pyttsx3.init()
        self.engine.setProperty("rate", 170)

        # Vosk
        self.model = Model(self.model_path)
        self.recognizer = KaldiRecognizer(self.model, self.sample_rate)

    # ================= éŸ³é¢‘å›è°ƒ =================
    def _audio_callback(self, indata, frames, time_info, status):
        if status:
            print(status)
        self.q.put(bytes(indata))

    def _tts_loop(self):
        while self.running:
            text = self.tts_queue.get()
            if text is None:
                continue
            with self.tts_lock:
                self.engine.say(text)
                self.engine.runAndWait()

    # ================= å…³é”®è¯åˆ¤æ–­ =================
    def _is_trigger(self, text: str) -> bool:
        return any(word in text for word in self.trigger_words)

    # ================= è¯­éŸ³æ’­æŠ¥ =================
    def _speak(self, text):
        self.tts_queue.put(text)

    # ================= ä¸»ç›‘å¬å¾ªç¯ =================
    def _listen_loop(self):
        with sd.RawInputStream(
            samplerate=self.sample_rate,
            blocksize=8000,
            dtype="int16",
            channels=1,
            callback=self._audio_callback,
        ):
            print("ğŸ™ è¯­éŸ³åŠ©æ‰‹å·²å¯åŠ¨ï¼ˆVosk æœ¬åœ°è¯†åˆ«ï¼‰")

            while self.running:
                data = self.q.get()
                if self.recognizer.AcceptWaveform(data):
                    result = json.loads(self.recognizer.Result())
                    text = result.get("text", "").strip()

                    if not text:
                        continue

                    print("ğŸ¤ è¯†åˆ«åˆ°ï¼š", text)

                    if not self._is_trigger(text):
                        continue

                    now = time.time()
                    if now - self.last_speak_time < self.cooldown:
                        continue

                    suggestion = self.get_suggestion()
                    if suggestion:
                        self._speak(suggestion)
                        self.last_speak_time = now

    # ================= å¯¹å¤–æ¥å£ =================
    def start(self):
        if self.running:
            return
        self.running = True

        threading.Thread(target=self._listen_loop, daemon=True).start()
        threading.Thread(target=self._tts_loop, daemon=True).start()

    def stop(self):
        self.running = False
